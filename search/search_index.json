{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 A collection of unexpected challenges and learnings with nextflow and nf-core . The provided examples reflect my journey in learning nextflow and generally assume an intermediate familiarity with nextflow. Gotchas \u00b6 The gotchas are typically provided as minimal, reproducible examples (MREs) with additional explanations. What is a minimal, reproducible example? As explained very well on StackOverflow : Your code examples should be Minimal \u2013 Use as little code as possible that still produces the same problem Complete \u2013 Provide all parts someone else needs to reproduce your problem in the question itself Reproducible \u2013 Test the code you're about to provide to make sure it reproduces the problem Errors \u00b6 Nextflow error messages and stack traces can, in all honesty, be quite maddening. Hopefully, yours is among the common ones that we describe here . Contributing \u00b6 Contributions are most welcome and I very much aim for this to be a community-driven project. In fact, most of the solutions provided here came from discussions on the nextflow or nf-core Slack . Both are incredible communities and I can only recommend that you join. Phil Ewels and I are already talking about how to best integrate these examples into the nf-core website . Please open an issue on the repository or message me on either of the Slack teams linked in the footer regarding any examples, ideas, or suggestions that you may have. Contributors \u2728 \u00b6 Thanks go to these wonderful people ( emoji key ): FriederikeHanssen \ud83d\udcd6 \ud83d\udca1 James A. Fellows Yates \ud83d\udcd6 \ud83d\udca1 Simon Pearce \ud83d\udcd6 \ud83d\udca1 This project follows the all-contributors specification. Contributions of any kind welcome! Acknowledgements \u00b6 As mentioned, nextflow has an amazing community. I want to mention a few people here who have been especially helpful in my interactions. In alphabetical order: Friederike Hanssen Harshil Patel Jose Espinosa-Carrasco Mahesh Binzer-Panchal Maxime U. Garcia Phil Ewels Pontus Freyhult Robert Syme If you feel that I forgot you in this list. Please let me know, it's not intentional! Copyright \u00b6 All examples and descriptions are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License .","title":"Introduction"},{"location":"#introduction","text":"A collection of unexpected challenges and learnings with nextflow and nf-core . The provided examples reflect my journey in learning nextflow and generally assume an intermediate familiarity with nextflow.","title":"Introduction"},{"location":"#gotchas","text":"The gotchas are typically provided as minimal, reproducible examples (MREs) with additional explanations. What is a minimal, reproducible example? As explained very well on StackOverflow : Your code examples should be Minimal \u2013 Use as little code as possible that still produces the same problem Complete \u2013 Provide all parts someone else needs to reproduce your problem in the question itself Reproducible \u2013 Test the code you're about to provide to make sure it reproduces the problem","title":"Gotchas"},{"location":"#errors","text":"Nextflow error messages and stack traces can, in all honesty, be quite maddening. Hopefully, yours is among the common ones that we describe here .","title":"Errors"},{"location":"#contributing","text":"Contributions are most welcome and I very much aim for this to be a community-driven project. In fact, most of the solutions provided here came from discussions on the nextflow or nf-core Slack . Both are incredible communities and I can only recommend that you join. Phil Ewels and I are already talking about how to best integrate these examples into the nf-core website . Please open an issue on the repository or message me on either of the Slack teams linked in the footer regarding any examples, ideas, or suggestions that you may have.","title":"Contributing"},{"location":"#contributors","text":"Thanks go to these wonderful people ( emoji key ): FriederikeHanssen \ud83d\udcd6 \ud83d\udca1 James A. Fellows Yates \ud83d\udcd6 \ud83d\udca1 Simon Pearce \ud83d\udcd6 \ud83d\udca1 This project follows the all-contributors specification. Contributions of any kind welcome!","title":"Contributors \u2728"},{"location":"#acknowledgements","text":"As mentioned, nextflow has an amazing community. I want to mention a few people here who have been especially helpful in my interactions. In alphabetical order: Friederike Hanssen Harshil Patel Jose Espinosa-Carrasco Mahesh Binzer-Panchal Maxime U. Garcia Phil Ewels Pontus Freyhult Robert Syme If you feel that I forgot you in this list. Please let me know, it's not intentional!","title":"Acknowledgements"},{"location":"#copyright","text":"All examples and descriptions are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License .","title":"Copyright"},{"location":"errors/","text":"Introduction \u00b6 Error messages and stack traces are probably the most intimidating whenever you start a new programming language. However, with nextflow there is an extra level of grief associated with coding errors. Nextflow is a domain specific language (DSL) for defining workflows built in Groovy/Java. That means that all the files actually are parsed and executed as Java code under the hood. In my experience, error messages and stack traces only vaguely point you in the direction of your mistakes and just as often confuse you more than they help you. As an example, I was working on a pipeline and forgot a comma in a configuration file. pipeline \u251c\u2500\u2500 conf \u2502 \u2514\u2500\u2500 modules.config # (1) \u2514\u2500\u2500 nextflow.config # (2) Here, I had forgotten a comma when configuring a process. process { withName: PROCESS { publishDir = [ mode: 'copy' pattern: '*.txt' ] } } The nextflow.config includes the conf/modules.config : includeConfig 'conf/modules.config' The error message that I got looked something like: Unable to parse config file: 'pipeline/nextflow.config' Compile failed for sources FixedSetSources[name='/groovy/script/Script804F3A5DC10BC08232AE23542F1477EC']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed: /groovy/script/Script804F3A5DC10BC08232AE23542F1477EC: 1: Unexpected input: '{' @ line 1, column 9. process { ^ 1 error So I knew it had to be a mistake inside of the process scope somewhere but that's not very helpful when I have several nested configuration files that each modify the process scope and I don't know what kind of error. Hopefully, the examples provided in the errors section can help you make sense of your own cryptic messages. Most of them are contributions from nf-core hackathon documentation .","title":"Introduction"},{"location":"errors/#introduction","text":"Error messages and stack traces are probably the most intimidating whenever you start a new programming language. However, with nextflow there is an extra level of grief associated with coding errors. Nextflow is a domain specific language (DSL) for defining workflows built in Groovy/Java. That means that all the files actually are parsed and executed as Java code under the hood. In my experience, error messages and stack traces only vaguely point you in the direction of your mistakes and just as often confuse you more than they help you. As an example, I was working on a pipeline and forgot a comma in a configuration file. pipeline \u251c\u2500\u2500 conf \u2502 \u2514\u2500\u2500 modules.config # (1) \u2514\u2500\u2500 nextflow.config # (2) Here, I had forgotten a comma when configuring a process. process { withName: PROCESS { publishDir = [ mode: 'copy' pattern: '*.txt' ] } } The nextflow.config includes the conf/modules.config : includeConfig 'conf/modules.config' The error message that I got looked something like: Unable to parse config file: 'pipeline/nextflow.config' Compile failed for sources FixedSetSources[name='/groovy/script/Script804F3A5DC10BC08232AE23542F1477EC']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed: /groovy/script/Script804F3A5DC10BC08232AE23542F1477EC: 1: Unexpected input: '{' @ line 1, column 9. process { ^ 1 error So I knew it had to be a mistake inside of the process scope somewhere but that's not very helpful when I have several nested configuration files that each modify the process scope and I don't know what kind of error. Hopefully, the examples provided in the errors section can help you make sense of your own cryptic messages. Most of them are contributions from nf-core hackathon documentation .","title":"Introduction"},{"location":"errors/dataflowvariable-assigned-once/","text":"DataflowVariable can only be assigned once \u00b6 Issue \u00b6 You get the following error, connected to a process Error executing process > 'PROCESS' Caused by: A DataflowVariable can only be assigned once. Only re-assignments to an equal value are allowed. Possible source \u00b6 You forgot the parentheses around a function like flatten() : PROCESS . out . vcfs . flatten","title":"DataflowVariable can only be assigned once"},{"location":"errors/dataflowvariable-assigned-once/#dataflowvariable-can-only-be-assigned-once","text":"","title":"DataflowVariable can only be assigned once"},{"location":"errors/dataflowvariable-assigned-once/#issue","text":"You get the following error, connected to a process Error executing process > 'PROCESS' Caused by: A DataflowVariable can only be assigned once. Only re-assignments to an equal value are allowed.","title":"Issue"},{"location":"errors/dataflowvariable-assigned-once/#possible-source","text":"You forgot the parentheses around a function like flatten() : PROCESS . out . vcfs . flatten","title":"Possible source"},{"location":"errors/dump-missing/","text":"Missing process or function with name dump \u00b6 Issue \u00b6 When using the .dump() function you get an error to console Missing process or function with name 'dump' Possible source \u00b6 In many cases, the function is not missing , just incorrectly applied. Missing tag: before the actual tag name (e.g. .dump('my tag') vs .dump(tag: 'my_tag') ) Placed on a channel-type that does not support the .dump function (e.g. channels with branches) .dump() was applied on a multi-channel output object without specifying which channel .dump() was applied on a single-channel, unnamed output directly. Usually, when a process defines a single output, unnamed channel, PROCESS_NAME.out (without specifying [0] ) works well with various nextflow operators, but, surprisingly, this way does not work well the dump operator. Quick workarounds could be i) using [0] to specify the channel explicitly, e.g. PROCESS_NAME.out[0] , ii) using named output, or iii) use a map operator before the dump operator. Examples can be found in issue #3","title":"Missing process or function with name dump"},{"location":"errors/dump-missing/#missing-process-or-function-with-name-dump","text":"","title":"Missing process or function with name dump"},{"location":"errors/dump-missing/#issue","text":"When using the .dump() function you get an error to console Missing process or function with name 'dump'","title":"Issue"},{"location":"errors/dump-missing/#possible-source","text":"In many cases, the function is not missing , just incorrectly applied. Missing tag: before the actual tag name (e.g. .dump('my tag') vs .dump(tag: 'my_tag') ) Placed on a channel-type that does not support the .dump function (e.g. channels with branches) .dump() was applied on a multi-channel output object without specifying which channel .dump() was applied on a single-channel, unnamed output directly. Usually, when a process defines a single output, unnamed channel, PROCESS_NAME.out (without specifying [0] ) works well with various nextflow operators, but, surprisingly, this way does not work well the dump operator. Quick workarounds could be i) using [0] to specify the channel explicitly, e.g. PROCESS_NAME.out[0] , ii) using named output, or iii) use a map operator before the dump operator. Examples can be found in issue #3","title":"Possible source"},{"location":"errors/id-null-object/","text":"Cannot get property id on null object \u00b6 Issue \u00b6 Console Execution aborted due to an unexpected error -- Check script '/home/jfellows/Documents/git/nf-core/taxprofiler/./workflows/../modules/nf-core/modules/kraken2/kraken2/main.nf' at line: 2 or see '.nextflow.log' file for more details Log java.lang.NullPointerException: Cannot get property 'id' on null object Possible source \u00b6 In most cases meta.id does exist, it is just not accessible by Nextflow in the way it expects to. Input channels not correctly passed to a module meta tuple is incorrectly nested (e.g. [[<meta>]] vs. [<meta>] ) Other parts of an input channel are incorrectly nested e.g. [meta] [[reads1.fq, reads2.fq]] when should be [meta] [reads1.fq, reads2.fq] Can also occur when meta.id tag is specified the tag block of a module, but meta is not supplied as input.","title":"Cannot get property id on null object"},{"location":"errors/id-null-object/#cannot-get-property-id-on-null-object","text":"","title":"Cannot get property id on null object"},{"location":"errors/id-null-object/#issue","text":"Console Execution aborted due to an unexpected error -- Check script '/home/jfellows/Documents/git/nf-core/taxprofiler/./workflows/../modules/nf-core/modules/kraken2/kraken2/main.nf' at line: 2 or see '.nextflow.log' file for more details Log java.lang.NullPointerException: Cannot get property 'id' on null object","title":"Issue"},{"location":"errors/id-null-object/#possible-source","text":"In most cases meta.id does exist, it is just not accessible by Nextflow in the way it expects to. Input channels not correctly passed to a module meta tuple is incorrectly nested (e.g. [[<meta>]] vs. [<meta>] ) Other parts of an input channel are incorrectly nested e.g. [meta] [[reads1.fq, reads2.fq]] when should be [meta] [reads1.fq, reads2.fq] Can also occur when meta.id tag is specified the tag block of a module, but meta is not supplied as input.","title":"Possible source"},{"location":"errors/mix-missing/","text":"Missing process or function with name mix \u00b6 Issue \u00b6 You get the follow error when using .mix() on channels Missing process or function with name 'mix' Possible source \u00b6 You passed a multi-channel output variable to .mix that causes this error: ch_scaffolds2bin_for_dastool . mix ( DASTOOL_SCAFFOLDS2BIN_METABAT2 . out . scaffolds2bin ) . mix ( DASTOOL_SCAFFOLDS2BIN_MAXBIN2 ) when you should've specified the particular .out channels ch_scaffolds2bin_for_dastool . mix ( DASTOOL_SCAFFOLDS2BIN_METABAT2 . out . scaffolds2bin ) . mix ( DASTOOL_SCAFFOLDS2BIN_MAXBIN2 . out . scaffolds2bin )","title":"Missing process or function with name mix"},{"location":"errors/mix-missing/#missing-process-or-function-with-name-mix","text":"","title":"Missing process or function with name mix"},{"location":"errors/mix-missing/#issue","text":"You get the follow error when using .mix() on channels Missing process or function with name 'mix'","title":"Issue"},{"location":"errors/mix-missing/#possible-source","text":"You passed a multi-channel output variable to .mix that causes this error: ch_scaffolds2bin_for_dastool . mix ( DASTOOL_SCAFFOLDS2BIN_METABAT2 . out . scaffolds2bin ) . mix ( DASTOOL_SCAFFOLDS2BIN_MAXBIN2 ) when you should've specified the particular .out channels ch_scaffolds2bin_for_dastool . mix ( DASTOOL_SCAFFOLDS2BIN_METABAT2 . out . scaffolds2bin ) . mix ( DASTOOL_SCAFFOLDS2BIN_MAXBIN2 . out . scaffolds2bin )","title":"Possible source"},{"location":"errors/module-compilation/","text":"Module compilation error \u00b6 Issue \u00b6 You get the following error, connected to the whole workflow - file : [PATH] - cause: Unexpected input: '{' @ line N, column N. - workflow [WORKFLOW] { Possible source \u00b6 You put two . next to each other, such as at the end of the first line and the start of the second: PROCESS . . out . bam . set { ch_bams }","title":"Module compilation error"},{"location":"errors/module-compilation/#module-compilation-error","text":"","title":"Module compilation error"},{"location":"errors/module-compilation/#issue","text":"You get the following error, connected to the whole workflow - file : [PATH] - cause: Unexpected input: '{' @ line N, column N. - workflow [WORKFLOW] {","title":"Issue"},{"location":"errors/module-compilation/#possible-source","text":"You put two . next to each other, such as at the end of the first line and the start of the second: PROCESS . . out . bam . set { ch_bams }","title":"Possible source"},{"location":"errors/multi-channel-operator/","text":"Multi-channel output cannot be applied to operator for which argument is already provided \u00b6 Issue \u00b6 You get an error such as Multi-channel output cannot be applied to operator mix for which argument is already provided Possible source \u00b6 You likely forgot to specify the output channel of a multi-channel output module or subworkflow, i.e., ch_output = MODULE_A ( input ) MODULE_B ( ch_output ) should be ch_output = MODULE_A ( input ). reads MODULE_B ( ch_output )","title":"Multi-channel output cannot be applied to operator for which argument is already provided"},{"location":"errors/multi-channel-operator/#multi-channel-output-cannot-be-applied-to-operator-for-which-argument-is-already-provided","text":"","title":"Multi-channel output cannot be applied to operator for which argument is already provided"},{"location":"errors/multi-channel-operator/#issue","text":"You get an error such as Multi-channel output cannot be applied to operator mix for which argument is already provided","title":"Issue"},{"location":"errors/multi-channel-operator/#possible-source","text":"You likely forgot to specify the output channel of a multi-channel output module or subworkflow, i.e., ch_output = MODULE_A ( input ) MODULE_B ( ch_output ) should be ch_output = MODULE_A ( input ). reads MODULE_B ( ch_output )","title":"Possible source"},{"location":"errors/unable-parse-config/","text":"Unable to parse config file \u00b6 Issue \u00b6 Unable to parse config file: 'nextflow.config' Compile failed for sources FixedSetSources[name='/groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed: /groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A: 432: Unexpected input: '{' @ line 432, column 8. process{ ^ Possible source \u00b6 Syntax error in modules.config , such as: Missing comma in publishDir Additional = after ext.<> directive Missing { or } somewhere Mentioned line numbers OR mentioned sign are not indicative of where to search for the error, i.e., in the above example the actual problem was a duplicated = .","title":"Unable to parse config file"},{"location":"errors/unable-parse-config/#unable-to-parse-config-file","text":"","title":"Unable to parse config file"},{"location":"errors/unable-parse-config/#issue","text":"Unable to parse config file: 'nextflow.config' Compile failed for sources FixedSetSources[name='/groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A']. Cause: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed: /groovy/script/Script7452FB2E4729BDF4899A4D4633CAE72A: 432: Unexpected input: '{' @ line 432, column 8. process{ ^","title":"Issue"},{"location":"errors/unable-parse-config/#possible-source","text":"Syntax error in modules.config , such as: Missing comma in publishDir Additional = after ext.<> directive Missing { or } somewhere Mentioned line numbers OR mentioned sign are not indicative of where to search for the error, i.e., in the above example the actual problem was a duplicated = .","title":"Possible source"},{"location":"gotchas/combine-list/","text":"Combine a list element \u00b6 Problem \u00b6 Say that you have a tool which takes a parameter and a bunch of files and does something with those. This is exemplified by the process CAT below. My first approach was to collect the files before combining them with the parameter. See the following workflow as an example. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out . collect () ) // (4) ch_input . map { row -> [ row . head ()] + row . tail (). collect { it . name } // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. The collect operator should turn this into a list. Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Here, I want to show the content of the resulting file which is the second of the pair in the output. Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/combine-list/problem.nf which gives the following output. It looks like the combine operator, when combining a single list of elements treats that just like a channel and forms the cartesian product with every element. There is also a warning about the input cardinality not matching the defined one in CAT and indeed we can see in the output that only one file is written to the result while the others are ignored. executor > local (8) [32/a72ef8] process > CREATE (1) [100%] 3 of 3 \u2714 [0a/dfd2e7] process > CAT (4) [100%] 5 of 5 \u2714 baz.txt bar.txt foo.txt [1, baz.txt, bar.txt, foo.txt] [2, baz.txt, bar.txt, foo.txt] [3, baz.txt, bar.txt, foo.txt] [4, baz.txt, bar.txt, foo.txt] [5, baz.txt, bar.txt, foo.txt] baz.txt Parameter: 1 baz.txt Parameter: 5 baz.txt Parameter: 2 baz.txt Parameter: 3 baz.txt Parameter: 4 WARN: Input tuple does not match input set cardinality declared by process `CAT` Solution \u00b6 Well, if a single list gets treated just like a channel, maybe we can nest that list such that we have a list with a single element that is also a list. I tried quite a few different ways: Can we collect twice? ch_input = ch_param . combine ( CREATE . out . collect (). collect () ) This does not work correctly. Just like in the problem, we get a flat list. What if we place it into a list manually? ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) This yields an error Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable which makes sense since we place the collected variable (of type DataflowVariable ) inside the literal list and thus it gets passed to our CAT process directly. Instead of collect there is also toList ... ch_input = ch_param . combine ( [ CREATE . out . toList () ] ) Same error Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable Then I got the correct advice: ch_input = ch_param . combine ( CREATE . out . toList (). toList () ) The corresponding comment on Slack was: Harshil Patel Don't ask me why. Turns out that the following combination also works. ch_input = ch_param . combine ( CREATE . out . collect (). toList () ) So in full the solution looks as follows. solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out . toList (). toList () ) // (4) ch_input . map { row -> [ row . head (), row . last (). collect { it . name }] // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. Use the winning solution from above. The toList operator applied twice creates the nested list. Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Again, I want to show the content of the resulting file which is the second of the pair in the output. Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/combine-list/solution.nf This time, both the shape of the input for CAT , as well as the content of the resulting files are as expected. executor > local (8) [0c/731285] process > CREATE (3) [100%] 3 of 3 \u2714 [e0/670c78] process > CAT (5) [100%] 5 of 5 \u2714 bar.txt foo.txt baz.txt [1, [bar.txt, foo.txt, baz.txt]] [2, [bar.txt, foo.txt, baz.txt]] [3, [bar.txt, foo.txt, baz.txt]] [4, [bar.txt, foo.txt, baz.txt]] [5, [bar.txt, foo.txt, baz.txt]] bar.txt foo.txt baz.txt Parameter: 3 bar.txt foo.txt baz.txt Parameter: 1 bar.txt foo.txt baz.txt Parameter: 4 bar.txt foo.txt baz.txt Parameter: 2 bar.txt foo.txt baz.txt Parameter: 5 Alternative solutions \u00b6 DataflowVariable value \u00b6 We saw above that the following code caused an error because we are passing a groovyx.gpars.dataflow.DataflowVariable to the process. ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) It is possible, though highly discouraged , to access a DataflowVariable 's inner value. ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) // (1) . map { first , second -> [ first , second . val ] } This combination generates pairs where the first element is the val and the second the DataflowVariable containing the list. Creating a list through transformation \u00b6 In our problem statement we saw: ch_input = ch_param . combine ( CREATE . out . collect () ) which created lists of four elements each. The parameter and the three files. We can transform this shape ourselves. ch_input = ch_param . combine ( CREATE . out . collect () ) . map { [ it . head (), it . tail ()] } Done Using combine and groupTuple \u00b6 A very different approach is to first combine every parameter value with every file. This generates pairs of one value and one file. We can then group the pairs together as tuples . group-tuple.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out ) // (4) . groupTuple () ch_input . map { row -> [ row . head (), row . last (). collect { it . name }] // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. Use combine on the flat channels to generate pairs. Then collect tuples of files by grouping the pairs by their first element, the numeric value, with groupTuple . Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Again, I want to show the content of the resulting file which is the second of the pair in the output. Run it NXF_VER = '21.10.6' nextflow run examples/combine-list/group-tuple.nf This generates the exact same solution. However, if you have a lot of elements in your channels this might perform slightly worse since you generate a lot more pairs first that you then have to group again. executor > local (8) [e9/c7a72b] process > CREATE (2) [100%] 3 of 3 \u2714 [cb/44c510] process > CAT (5) [100%] 5 of 5 \u2714 baz.txt foo.txt bar.txt [1, [baz.txt, foo.txt, bar.txt]] [2, [baz.txt, foo.txt, bar.txt]] [3, [baz.txt, foo.txt, bar.txt]] [4, [baz.txt, foo.txt, bar.txt]] [5, [baz.txt, foo.txt, bar.txt]] baz.txt foo.txt bar.txt Parameter: 4 baz.txt foo.txt bar.txt Parameter: 2 baz.txt foo.txt bar.txt Parameter: 3 baz.txt foo.txt bar.txt Parameter: 1 baz.txt foo.txt bar.txt Parameter: 5","title":"Combine a list element"},{"location":"gotchas/combine-list/#combine-a-list-element","text":"","title":"Combine a list element"},{"location":"gotchas/combine-list/#problem","text":"Say that you have a tool which takes a parameter and a bunch of files and does something with those. This is exemplified by the process CAT below. My first approach was to collect the files before combining them with the parameter. See the following workflow as an example. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out . collect () ) // (4) ch_input . map { row -> [ row . head ()] + row . tail (). collect { it . name } // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. The collect operator should turn this into a list. Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Here, I want to show the content of the resulting file which is the second of the pair in the output. Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/combine-list/problem.nf which gives the following output. It looks like the combine operator, when combining a single list of elements treats that just like a channel and forms the cartesian product with every element. There is also a warning about the input cardinality not matching the defined one in CAT and indeed we can see in the output that only one file is written to the result while the others are ignored. executor > local (8) [32/a72ef8] process > CREATE (1) [100%] 3 of 3 \u2714 [0a/dfd2e7] process > CAT (4) [100%] 5 of 5 \u2714 baz.txt bar.txt foo.txt [1, baz.txt, bar.txt, foo.txt] [2, baz.txt, bar.txt, foo.txt] [3, baz.txt, bar.txt, foo.txt] [4, baz.txt, bar.txt, foo.txt] [5, baz.txt, bar.txt, foo.txt] baz.txt Parameter: 1 baz.txt Parameter: 5 baz.txt Parameter: 2 baz.txt Parameter: 3 baz.txt Parameter: 4 WARN: Input tuple does not match input set cardinality declared by process `CAT`","title":"Problem"},{"location":"gotchas/combine-list/#solution","text":"Well, if a single list gets treated just like a channel, maybe we can nest that list such that we have a list with a single element that is also a list. I tried quite a few different ways: Can we collect twice? ch_input = ch_param . combine ( CREATE . out . collect (). collect () ) This does not work correctly. Just like in the problem, we get a flat list. What if we place it into a list manually? ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) This yields an error Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable which makes sense since we place the collected variable (of type DataflowVariable ) inside the literal list and thus it gets passed to our CAT process directly. Instead of collect there is also toList ... ch_input = ch_param . combine ( [ CREATE . out . toList () ] ) Same error Not a valid path value type: groovyx.gpars.dataflow.DataflowVariable Then I got the correct advice: ch_input = ch_param . combine ( CREATE . out . toList (). toList () ) The corresponding comment on Slack was: Harshil Patel Don't ask me why. Turns out that the following combination also works. ch_input = ch_param . combine ( CREATE . out . collect (). toList () ) So in full the solution looks as follows. solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out . toList (). toList () ) // (4) ch_input . map { row -> [ row . head (), row . last (). collect { it . name }] // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. Use the winning solution from above. The toList operator applied twice creates the nested list. Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Again, I want to show the content of the resulting file which is the second of the pair in the output. Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/combine-list/solution.nf This time, both the shape of the input for CAT , as well as the content of the resulting files are as expected. executor > local (8) [0c/731285] process > CREATE (3) [100%] 3 of 3 \u2714 [e0/670c78] process > CAT (5) [100%] 5 of 5 \u2714 bar.txt foo.txt baz.txt [1, [bar.txt, foo.txt, baz.txt]] [2, [bar.txt, foo.txt, baz.txt]] [3, [bar.txt, foo.txt, baz.txt]] [4, [bar.txt, foo.txt, baz.txt]] [5, [bar.txt, foo.txt, baz.txt]] bar.txt foo.txt baz.txt Parameter: 3 bar.txt foo.txt baz.txt Parameter: 1 bar.txt foo.txt baz.txt Parameter: 4 bar.txt foo.txt baz.txt Parameter: 2 bar.txt foo.txt baz.txt Parameter: 5","title":"Solution"},{"location":"gotchas/combine-list/#alternative-solutions","text":"","title":"Alternative solutions"},{"location":"gotchas/combine-list/#dataflowvariable-value","text":"We saw above that the following code caused an error because we are passing a groovyx.gpars.dataflow.DataflowVariable to the process. ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) It is possible, though highly discouraged , to access a DataflowVariable 's inner value. ch_input = ch_param . combine ( [ CREATE . out . collect () ] ) // (1) . map { first , second -> [ first , second . val ] } This combination generates pairs where the first element is the val and the second the DataflowVariable containing the list.","title":"DataflowVariable value"},{"location":"gotchas/combine-list/#creating-a-list-through-transformation","text":"In our problem statement we saw: ch_input = ch_param . combine ( CREATE . out . collect () ) which created lists of four elements each. The parameter and the three files. We can transform this shape ourselves. ch_input = ch_param . combine ( CREATE . out . collect () ) . map { [ it . head (), it . tail ()] } Done","title":"Creating a list through transformation"},{"location":"gotchas/combine-list/#using-combine-and-grouptuple","text":"A very different approach is to first combine every parameter value with every file. This generates pairs of one value and one file. We can then group the pairs together as tuples . group-tuple.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process CREATE { input: val filename output: path filename script: // (1) \"\"\" echo ${filename} > ${filename} \"\"\" } process CAT { input: tuple val ( number ), path ( files ) output: tuple val ( number ), path ( 'result.txt' ) script: // (2) \"\"\" cat ${files} > result.txt echo 'Parameter: ${number}' >> result.txt \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_param = Channel . of ( 1 .. 5 ) ch_files = Channel . of ( 'foo.txt' , 'bar.txt' , 'baz.txt' ) CREATE ( ch_files ) CREATE . out . map { it . name } . view () // (3) ch_input = ch_param . combine ( CREATE . out ) // (4) . groupTuple () ch_input . map { row -> [ row . head (), row . last (). collect { it . name }] // (5) } . view () CAT ( ch_input ) CAT . out . map { it [ 1 ]. text }. view () // (6) } Create a file with distinct content. Concatenate all files into one and use the parameter value. For better display, I'm only showing the filenames here and not the whole paths. Use combine on the flat channels to generate pairs. Then collect tuples of files by grouping the pairs by their first element, the numeric value, with groupTuple . Don't worry too much about this, I'm again transforming the output to only display filenames and not the entire paths. Again, I want to show the content of the resulting file which is the second of the pair in the output. Run it NXF_VER = '21.10.6' nextflow run examples/combine-list/group-tuple.nf This generates the exact same solution. However, if you have a lot of elements in your channels this might perform slightly worse since you generate a lot more pairs first that you then have to group again. executor > local (8) [e9/c7a72b] process > CREATE (2) [100%] 3 of 3 \u2714 [cb/44c510] process > CAT (5) [100%] 5 of 5 \u2714 baz.txt foo.txt bar.txt [1, [baz.txt, foo.txt, bar.txt]] [2, [baz.txt, foo.txt, bar.txt]] [3, [baz.txt, foo.txt, bar.txt]] [4, [baz.txt, foo.txt, bar.txt]] [5, [baz.txt, foo.txt, bar.txt]] baz.txt foo.txt bar.txt Parameter: 4 baz.txt foo.txt bar.txt Parameter: 2 baz.txt foo.txt bar.txt Parameter: 3 baz.txt foo.txt bar.txt Parameter: 1 baz.txt foo.txt bar.txt Parameter: 5","title":"Using combine and groupTuple"},{"location":"gotchas/script-order-of-operators/","text":"Ordering of operators in a script \u00b6 Problem \u00b6 In many cases, the order in which you define steps of a Nextflow script does not influence the order of execution. This is due to the nature of the process and channel dataflow paradigm used by Nextflow. In contrast, where a Nextflow operator is placed within a script does influence when it is executed. One such example is the mix ing of channels together prior passing it to a process. If a .mix() is specified after the execution of a process that uses that channel, the contents of that particular .mix() will not be included in the execution of the process. A good example of this is nf-core version reporting. In nf-core pipelines, a 'commmon' channel ( ch_versions ) is created early in the pipeline script. When each process is executed, a versions file from that process is then mix ed into this common channel. Finally, this common channel containing all versions files is sent to a process ( CUSTOM_DUMPSOFTWAREVERSIONS ) that aggregates all versions into a single file. In the example below, the mix ing of the BAR process' version file into ch_versions is defined to happen after CUSTOM_DUMPSOFTWAREVERSIONS . In this case, the version of BAR would not be included in the execution/output of the CUSTOM_DUMPSOFTWAREVERSIONS process. ch_versions = Channel.empty() FOO( input ) BAR( input ) ch_versions = ch_versions.mix( FOO.out.versions ) CUSTOM_DUMPSOFTWAREVERSIONS ( ch_versions ) ch_versions = ch_versions.mix( BAR.out.versions ) The output file of CUSTOM_DUMPSOFTWAREVERSIONS would look like FOO: foo: '1.0.0' whereby the BAR version is not included in the file. Solution \u00b6 Ensure that all mix ing invocations are defined in the script prior to the process the subsequent channel will be included in. ch_versions = Channel.empty() FOO( input ) BAR( input ) ch_versions = ch_versions.mix( FOO.out.versions ) ch_versions = ch_versions.mix( BAR.out.versions ) CUSTOM_DUMPSOFTWAREVERSIONS ( ch_versions ) In this case the versions of both FOO and BAR will be displayed FOO: foo: '1.0.0' BAR: bar: '2.0.0'","title":"Ordering of operators in a script"},{"location":"gotchas/script-order-of-operators/#ordering-of-operators-in-a-script","text":"","title":"Ordering of operators in a script"},{"location":"gotchas/script-order-of-operators/#problem","text":"In many cases, the order in which you define steps of a Nextflow script does not influence the order of execution. This is due to the nature of the process and channel dataflow paradigm used by Nextflow. In contrast, where a Nextflow operator is placed within a script does influence when it is executed. One such example is the mix ing of channels together prior passing it to a process. If a .mix() is specified after the execution of a process that uses that channel, the contents of that particular .mix() will not be included in the execution of the process. A good example of this is nf-core version reporting. In nf-core pipelines, a 'commmon' channel ( ch_versions ) is created early in the pipeline script. When each process is executed, a versions file from that process is then mix ed into this common channel. Finally, this common channel containing all versions files is sent to a process ( CUSTOM_DUMPSOFTWAREVERSIONS ) that aggregates all versions into a single file. In the example below, the mix ing of the BAR process' version file into ch_versions is defined to happen after CUSTOM_DUMPSOFTWAREVERSIONS . In this case, the version of BAR would not be included in the execution/output of the CUSTOM_DUMPSOFTWAREVERSIONS process. ch_versions = Channel.empty() FOO( input ) BAR( input ) ch_versions = ch_versions.mix( FOO.out.versions ) CUSTOM_DUMPSOFTWAREVERSIONS ( ch_versions ) ch_versions = ch_versions.mix( BAR.out.versions ) The output file of CUSTOM_DUMPSOFTWAREVERSIONS would look like FOO: foo: '1.0.0' whereby the BAR version is not included in the file.","title":"Problem"},{"location":"gotchas/script-order-of-operators/#solution","text":"Ensure that all mix ing invocations are defined in the script prior to the process the subsequent channel will be included in. ch_versions = Channel.empty() FOO( input ) BAR( input ) ch_versions = ch_versions.mix( FOO.out.versions ) ch_versions = ch_versions.mix( BAR.out.versions ) CUSTOM_DUMPSOFTWAREVERSIONS ( ch_versions ) In this case the versions of both FOO and BAR will be displayed FOO: foo: '1.0.0' BAR: bar: '2.0.0'","title":"Solution"},{"location":"gotchas/shallow-copy/","text":"Modifying mutable elements \u00b6 Problem \u00b6 When working with nf-core modules , a ubiquitous pattern is to pass around sample metadata as a maps . Maps are mutable objects. In nextflow DSL2 , you can reuse a channel. This creates a shallow copy of the channel's elements which can lead to surprising behavior in combination with mutable objects. To see this in action run the first example. echo.nf 1 2 3 4 5 6 7 8 9 10 11 process ECHO { input: val meta output: val meta \"\"\" echo '${meta.id}' \"\"\" } problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Import processes ******************************************************************************/ include { ECHO as ECHO1 ; ECHO as ECHO2 ; } from './echo' /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { def ch_input = Channel . of ([ id: 'test1' , idx: 1 ], [ id: 'test2' , idx: 2 ]) ECHO1 ( ch_input ). view () ECHO2 ( ch_input . map { meta -> meta . id = 'foo' meta } ). view () } Notice that we are modifying the id attribute of the maps. NXF_VER = '21.10.6' nextflow run examples/shallow-copy/problem.nf executor > local (4) [10/bbc389] process > ECHO1 (2) [100%] 2 of 2 \u2714 [fa/3f7585] process > ECHO2 (2) [100%] 2 of 2 \u2714 [id:foo, idx:1] [id:foo, idx:1] [id:foo, idx:2] [id:foo, idx:2] The channel ch_input contains two elements which are both maps. The channel is passed to a process ECHO1 and then reused and modified before being passed to the process ECHO2 . Intuitively, we would expect the reuse to copy the channel and thus be independent of the first use. However, due to nextflow being asynchronous and shallow copying the channels, we can see that all maps are modified. Solution \u00b6 In order to achieve the desired outcome of the reused channel being independent of the first use, we need to clone the mutable element. This then creates a shallow of the mutable element itself which can be modified independently. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Import processes ******************************************************************************/ include { ECHO as ECHO1 ; ECHO as ECHO2 ; } from './echo' /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { def ch_input = Channel . of ([ id: 'test1' , idx: 1 ], [ id: 'test2' , idx: 2 ]) ECHO1 ( ch_input ). view () ECHO2 ( ch_input . map { meta -> def copy = meta . clone () copy . id = 'foo' return copy } ). view () } To see the outcome, run the following: NXF_VER = '21.10.6' nextflow run examples/shallow-copy/solution.nf executor > local (4) [0e/0b1e55] process > ECHO1 (1) [100%] 2 of 2 \u2714 [f6/4e9656] process > ECHO2 (2) [100%] 2 of 2 \u2714 [id:foo, idx:1] [id:test2, idx:2] [id:test1, idx:1] [id:foo, idx:2] In some cases where you have nested mutable objects you may have to create a deep copy .","title":"Modifying mutable elements"},{"location":"gotchas/shallow-copy/#modifying-mutable-elements","text":"","title":"Modifying mutable elements"},{"location":"gotchas/shallow-copy/#problem","text":"When working with nf-core modules , a ubiquitous pattern is to pass around sample metadata as a maps . Maps are mutable objects. In nextflow DSL2 , you can reuse a channel. This creates a shallow copy of the channel's elements which can lead to surprising behavior in combination with mutable objects. To see this in action run the first example. echo.nf 1 2 3 4 5 6 7 8 9 10 11 process ECHO { input: val meta output: val meta \"\"\" echo '${meta.id}' \"\"\" } problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Import processes ******************************************************************************/ include { ECHO as ECHO1 ; ECHO as ECHO2 ; } from './echo' /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { def ch_input = Channel . of ([ id: 'test1' , idx: 1 ], [ id: 'test2' , idx: 2 ]) ECHO1 ( ch_input ). view () ECHO2 ( ch_input . map { meta -> meta . id = 'foo' meta } ). view () } Notice that we are modifying the id attribute of the maps. NXF_VER = '21.10.6' nextflow run examples/shallow-copy/problem.nf executor > local (4) [10/bbc389] process > ECHO1 (2) [100%] 2 of 2 \u2714 [fa/3f7585] process > ECHO2 (2) [100%] 2 of 2 \u2714 [id:foo, idx:1] [id:foo, idx:1] [id:foo, idx:2] [id:foo, idx:2] The channel ch_input contains two elements which are both maps. The channel is passed to a process ECHO1 and then reused and modified before being passed to the process ECHO2 . Intuitively, we would expect the reuse to copy the channel and thus be independent of the first use. However, due to nextflow being asynchronous and shallow copying the channels, we can see that all maps are modified.","title":"Problem"},{"location":"gotchas/shallow-copy/#solution","text":"In order to achieve the desired outcome of the reused channel being independent of the first use, we need to clone the mutable element. This then creates a shallow of the mutable element itself which can be modified independently. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Import processes ******************************************************************************/ include { ECHO as ECHO1 ; ECHO as ECHO2 ; } from './echo' /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { def ch_input = Channel . of ([ id: 'test1' , idx: 1 ], [ id: 'test2' , idx: 2 ]) ECHO1 ( ch_input ). view () ECHO2 ( ch_input . map { meta -> def copy = meta . clone () copy . id = 'foo' return copy } ). view () } To see the outcome, run the following: NXF_VER = '21.10.6' nextflow run examples/shallow-copy/solution.nf executor > local (4) [0e/0b1e55] process > ECHO1 (1) [100%] 2 of 2 \u2714 [f6/4e9656] process > ECHO2 (2) [100%] 2 of 2 \u2714 [id:foo, idx:1] [id:test2, idx:2] [id:test1, idx:1] [id:foo, idx:2] In some cases where you have nested mutable objects you may have to create a deep copy .","title":"Solution"},{"location":"gotchas/shell-global-only/","text":"Global variables only in shell blocks \u00b6 Problem \u00b6 A very common pattern when working with nf-core modules is to define local arguments for a command. This pattern allows for defining some process-local defaults, as well as the ability to override those defaults from a configuration file. Take the gunzip module , for example, it defines empty default arguments. gunzip/main.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 process GUNZIP { tag \"$archive\" label 'process_low' conda ( params . enable_conda ? \"conda-forge::sed=4.7\" : null ) container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' : 'biocontainers/biocontainers:v1.2.0_cv1' }\" input: tuple val ( meta ), path ( archive ) output: tuple val ( meta ), path ( \"$gunzip\" ), emit: gunzip path \"versions.yml\" , emit: versions when: task . ext . when == null || task . ext . when script: def args = task . ext . args ?: '' gunzip = archive . toString () - '.gz' \"\"\" gunzip \\\\ -f \\\\ $args \\\\ $archive cat <<-END_VERSIONS > versions.yml \"${task.process}\": gunzip: \\$(echo \\$(gunzip --version 2>&1) | sed 's/^.*(gzip) //; s/ Copyright.*\\$//') END_VERSIONS \"\"\" } I can then override the default arguments with additional options in a configuration file such as a pipeline's conf/modules.config . conf/modules.config process { withName: GUNZIP { ext . args = '--keep' } } The other day, I needed to use a shell block instead of the normal script block but I hit a snag; my args were being replaced with [] ?! You can try this yourself by running the following workflow. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { echo true shell: def args = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: args: ${args} \"\"\" ''' echo !{args} ''' } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/problem.nf When you do so, you should see output like: executor > local (1) [97/a1e136] process > ECHO [100%] 1 of 1 \u2714 ECHO: task.ext.args: null ECHO: args: bar [] As you will see from the output, args contains the correct value bar but the final output is [] . Exploration \u00b6 That made me wonder, \"Is the args variable special somehow?\" The name is easily changed to foo which you can try yourself. exploration.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 process ECHO { echo true shell: def foo = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: foo: ${args} \"\"\" ''' echo !{foo} ''' } workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/exploration.nf And big, fat error. Error executing process > 'ECHO_LOCAL_FOO' Caused by: No such variable: foo Source block: def foo = task.ext.args ?: 'bar' log.info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: foo: ${foo} \"\"\" ''' echo !{foo} ''' This was the clue I needed to find a solution. Solution \u00b6 There are a couple of gotchas in nextflow with locally scoped variables (variables defined with def ). So why not try with a process global? Removing the def keyword finally made the process run as expected. You can see for yourself by running the following: solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 process ECHO { echo true shell: args = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: args: ${args} \"\"\" ''' echo !{args} ''' } workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/solution.nf executor > local (1) [ba/0e5d39] process > ECHO [100%] 1 of 1 \u2714 ECHO: task.ext.args: null ECHO: args: bar bar Smooth","title":"Global variables only in shell blocks"},{"location":"gotchas/shell-global-only/#global-variables-only-in-shell-blocks","text":"","title":"Global variables only in shell blocks"},{"location":"gotchas/shell-global-only/#problem","text":"A very common pattern when working with nf-core modules is to define local arguments for a command. This pattern allows for defining some process-local defaults, as well as the ability to override those defaults from a configuration file. Take the gunzip module , for example, it defines empty default arguments. gunzip/main.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 process GUNZIP { tag \"$archive\" label 'process_low' conda ( params . enable_conda ? \"conda-forge::sed=4.7\" : null ) container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' : 'biocontainers/biocontainers:v1.2.0_cv1' }\" input: tuple val ( meta ), path ( archive ) output: tuple val ( meta ), path ( \"$gunzip\" ), emit: gunzip path \"versions.yml\" , emit: versions when: task . ext . when == null || task . ext . when script: def args = task . ext . args ?: '' gunzip = archive . toString () - '.gz' \"\"\" gunzip \\\\ -f \\\\ $args \\\\ $archive cat <<-END_VERSIONS > versions.yml \"${task.process}\": gunzip: \\$(echo \\$(gunzip --version 2>&1) | sed 's/^.*(gzip) //; s/ Copyright.*\\$//') END_VERSIONS \"\"\" } I can then override the default arguments with additional options in a configuration file such as a pipeline's conf/modules.config . conf/modules.config process { withName: GUNZIP { ext . args = '--keep' } } The other day, I needed to use a shell block instead of the normal script block but I hit a snag; my args were being replaced with [] ?! You can try this yourself by running the following workflow. problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { echo true shell: def args = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: args: ${args} \"\"\" ''' echo !{args} ''' } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/problem.nf When you do so, you should see output like: executor > local (1) [97/a1e136] process > ECHO [100%] 1 of 1 \u2714 ECHO: task.ext.args: null ECHO: args: bar [] As you will see from the output, args contains the correct value bar but the final output is [] .","title":"Problem"},{"location":"gotchas/shell-global-only/#exploration","text":"That made me wonder, \"Is the args variable special somehow?\" The name is easily changed to foo which you can try yourself. exploration.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 process ECHO { echo true shell: def foo = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: foo: ${args} \"\"\" ''' echo !{foo} ''' } workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/exploration.nf And big, fat error. Error executing process > 'ECHO_LOCAL_FOO' Caused by: No such variable: foo Source block: def foo = task.ext.args ?: 'bar' log.info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: foo: ${foo} \"\"\" ''' echo !{foo} ''' This was the clue I needed to find a solution.","title":"Exploration"},{"location":"gotchas/shell-global-only/#solution","text":"There are a couple of gotchas in nextflow with locally scoped variables (variables defined with def ). So why not try with a process global? Removing the def keyword finally made the process run as expected. You can see for yourself by running the following: solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 process ECHO { echo true shell: args = task . ext . args ?: 'bar' log . info \"\"\" ${task.process}: task.ext.args: ${task.ext.args} ${task.process}: args: ${args} \"\"\" ''' echo !{args} ''' } workflow { ECHO () } NXF_VER = '21.10.6' nextflow run examples/shell-global-copy/solution.nf executor > local (1) [ba/0e5d39] process > ECHO [100%] 1 of 1 \u2714 ECHO: task.ext.args: null ECHO: args: bar bar Smooth","title":"Solution"},{"location":"gotchas/singleton-channel/","text":"Exhausting single element channels \u00b6 Problem \u00b6 Processes that accept more than one argument, will be executed as many times as the smaller number of elements in either channel, for example, if you have a channel with five elements and another with two elements, the process will be called twice. If you have a channel with a single element, it is not reused automatically but the process is executed just once. This can be surprising because nextflow in DSL2 copies channels as needed . problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_variadic = Channel . of ( 1 .. 20 ) ch_singleton = Channel . of ( 'arg' ) ECHO ( ch_variadic , ch_singleton ) } Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/singleton-channel/problem.nf which gives the following output, the process is just called once. executor > local (1) [b5/7c55cf] process > ECHO (1) [100%] 1 of 1 \u2714 Solution \u00b6 Channels can be turned into value channels which can never be exhausted and read an unlimited number of times. A simple way to do this is by applying the operator first . solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_variadic = Channel . of ( 1 .. 20 ) ch_singleton = Channel . of ( 'arg' ) ECHO ( ch_variadic , ch_singleton . first ()) } You can see the difference by running the workflow. NXF_VER = '21.10.6' nextflow run examples/singleton-channel/solution.nf executor > local (20) [02/fa180f] process > ECHO (20) [100%] 20 of 20 \u2714 Please note the following admonition from the nextflow documentation: Note A value channel is implicitly created by a process when an input specifies a simple value in the from clause. Moreover, a value channel is also implicitly created as output for a process whose inputs are only value channels. This means that a process that gets passed a value and, for example, downloads a file, implicitly has a value channel created for that file and it can be reused indefinitely. Combinations \u00b6 If you have multiple channels of different numbers of elements but more than one element such that a value channel is not an option, you can apply some transformations to achieve the correct outcome. combinations.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_long = Channel . of ( 1 .. 20 ) ch_short = Channel . of ( 31 .. 33 ) ch_combined = ch_long . combine ( ch_short ) . multiMap { first: it [ 0 ] second: it [ 1 ] } ECHO ( ch_combined . first , ch_combined . second ) } In this workflow, combine does most of the work, as it combines each element from one channel with every element of the other channel. Afterwards, we use multiMap to split the pairs into two separate channels that we can pass to the process which expects two arguments. You can see the difference by running the workflow. NXF_VER = '21.10.6' nextflow run examples/singleton-channel/combinations.nf Combinatorics, wheee executor > local (60) [09/71172f] process > ECHO (60) [100%] 60 of 60 \u2714","title":"Exhausting single element channels"},{"location":"gotchas/singleton-channel/#exhausting-single-element-channels","text":"","title":"Exhausting single element channels"},{"location":"gotchas/singleton-channel/#problem","text":"Processes that accept more than one argument, will be executed as many times as the smaller number of elements in either channel, for example, if you have a channel with five elements and another with two elements, the process will be called twice. If you have a channel with a single element, it is not reused automatically but the process is executed just once. This can be surprising because nextflow in DSL2 copies channels as needed . problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_variadic = Channel . of ( 1 .. 20 ) ch_singleton = Channel . of ( 'arg' ) ECHO ( ch_variadic , ch_singleton ) } Run the above workflow with: NXF_VER = '21.10.6' nextflow run examples/singleton-channel/problem.nf which gives the following output, the process is just called once. executor > local (1) [b5/7c55cf] process > ECHO (1) [100%] 1 of 1 \u2714","title":"Problem"},{"location":"gotchas/singleton-channel/#solution","text":"Channels can be turned into value channels which can never be exhausted and read an unlimited number of times. A simple way to do this is by applying the operator first . solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_variadic = Channel . of ( 1 .. 20 ) ch_singleton = Channel . of ( 'arg' ) ECHO ( ch_variadic , ch_singleton . first ()) } You can see the difference by running the workflow. NXF_VER = '21.10.6' nextflow run examples/singleton-channel/solution.nf executor > local (20) [02/fa180f] process > ECHO (20) [100%] 20 of 20 \u2714 Please note the following admonition from the nextflow documentation: Note A value channel is implicitly created by a process when an input specifies a simple value in the from clause. Moreover, a value channel is also implicitly created as output for a process whose inputs are only value channels. This means that a process that gets passed a value and, for example, downloads a file, implicitly has a value channel created for that file and it can be reused indefinitely.","title":"Solution"},{"location":"gotchas/singleton-channel/#combinations","text":"If you have multiple channels of different numbers of elements but more than one element such that a value channel is not an option, you can apply some transformations to achieve the correct outcome. combinations.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( number ) val ( data ) \"\"\" echo ${number}-${data} \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ch_long = Channel . of ( 1 .. 20 ) ch_short = Channel . of ( 31 .. 33 ) ch_combined = ch_long . combine ( ch_short ) . multiMap { first: it [ 0 ] second: it [ 1 ] } ECHO ( ch_combined . first , ch_combined . second ) } In this workflow, combine does most of the work, as it combines each element from one channel with every element of the other channel. Afterwards, we use multiMap to split the pairs into two separate channels that we can pass to the process which expects two arguments. You can see the difference by running the workflow. NXF_VER = '21.10.6' nextflow run examples/singleton-channel/combinations.nf Combinatorics, wheee executor > local (60) [09/71172f] process > ECHO (60) [100%] 60 of 60 \u2714","title":"Combinations"},{"location":"gotchas/variable-scope/","text":"Variable scope \u00b6 Under most circumstances it is recommended to use local variable scope. In Groovy and thus nextflow, you do this with the def keyword. However, there are some situations where this can be awkward or even surprising. Conditionals \u00b6 In the following workflow, the variable message is declared local to the if statement and cannot be accessed outside it. if.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { if ( true ) { def message = 'Hello... noone?' } def ch = Channel . of ( message ) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/if.nf No such variable: message -- Check script 'examples/variable-scope/problem.nf' at line: 13 or see '.nextflow.log' file for more details Process blocks \u00b6 Problem \u00b6 In my mental model, a nextflow process is very much a logical unit. However, a process consists of up to five blocks and variables local to one block, cannot be used in another. As an example: process-problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process TOUCH { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: def result = \"${meta.id}.txt\" \"\"\" touch '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { TOUCH ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/process-problem.nf executor > local (1) [28/98c503] process > TOUCH [100%] 1 of 1, failed: 1 \u2718 Error executing process > 'TOUCH' Caused by: Missing output file(s) `result` expected by process `TOUCH` Command executed: touch 'snafu.txt' Command exit status: 0 Command output: (empty) Solution \u00b6 It is an error to use the result variable which was declared local to the script block, in any other block. One may want to use a variable defined in the script block in the output block. In that case, you have to remove the def keyword to make it global. process-solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process TOUCH { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" \"\"\" touch '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { TOUCH ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/process-solution.nf executor > local (1) [f4/263762] process > TOUCH [100%] 1 of 1 \u2714 Mixing variables \u00b6 Additionally, if you use a variable with global scope in the assignment of a variable with local scope, this is also an error. mixing-problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" def choice = result . startsWith ( 'snafu' ) ? 'yes' : 'no' \"\"\" echo '${choice}' > '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/mixing-problem.nf Script compilation error - cause: Variable `result` already defined in the process scope @ line 19, column 18. def choice = result.startsWith('snafu') ? 'yes' : 'no' ^ That means, any variable that uses a global in its assignment, has to be global also. mixing-solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" choice = result . startsWith ( 'snafu' ) ? 'yes' : 'no' \"\"\" echo '${choice}' > '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/mixing-solution.nf executor > local (1) [c2/70f706] process > ECHO [100%] 1 of 1 \u2714 Hope this helps, it can be quite baffling.","title":"Variable scope"},{"location":"gotchas/variable-scope/#variable-scope","text":"Under most circumstances it is recommended to use local variable scope. In Groovy and thus nextflow, you do this with the def keyword. However, there are some situations where this can be awkward or even surprising.","title":"Variable scope"},{"location":"gotchas/variable-scope/#conditionals","text":"In the following workflow, the variable message is declared local to the if statement and cannot be accessed outside it. if.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { if ( true ) { def message = 'Hello... noone?' } def ch = Channel . of ( message ) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/if.nf No such variable: message -- Check script 'examples/variable-scope/problem.nf' at line: 13 or see '.nextflow.log' file for more details","title":"Conditionals"},{"location":"gotchas/variable-scope/#process-blocks","text":"","title":"Process blocks"},{"location":"gotchas/variable-scope/#problem","text":"In my mental model, a nextflow process is very much a logical unit. However, a process consists of up to five blocks and variables local to one block, cannot be used in another. As an example: process-problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process TOUCH { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: def result = \"${meta.id}.txt\" \"\"\" touch '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { TOUCH ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/process-problem.nf executor > local (1) [28/98c503] process > TOUCH [100%] 1 of 1, failed: 1 \u2718 Error executing process > 'TOUCH' Caused by: Missing output file(s) `result` expected by process `TOUCH` Command executed: touch 'snafu.txt' Command exit status: 0 Command output: (empty)","title":"Problem"},{"location":"gotchas/variable-scope/#solution","text":"It is an error to use the result variable which was declared local to the script block, in any other block. One may want to use a variable defined in the script block in the output block. In that case, you have to remove the def keyword to make it global. process-solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process TOUCH { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" \"\"\" touch '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { TOUCH ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/process-solution.nf executor > local (1) [f4/263762] process > TOUCH [100%] 1 of 1 \u2714","title":"Solution"},{"location":"gotchas/variable-scope/#mixing-variables","text":"Additionally, if you use a variable with global scope in the assignment of a variable with local scope, this is also an error. mixing-problem.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" def choice = result . startsWith ( 'snafu' ) ? 'yes' : 'no' \"\"\" echo '${choice}' > '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/mixing-problem.nf Script compilation error - cause: Variable `result` already defined in the process scope @ line 19, column 18. def choice = result.startsWith('snafu') ? 'yes' : 'no' ^ That means, any variable that uses a global in its assignment, has to be global also. mixing-solution.nf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/usr/bin/env nextflow nextflow . enable . dsl = 2 /******************************************************************************* * Define processes ******************************************************************************/ process ECHO { input: val ( meta ) output: tuple val ( meta ), path ( result ) script: result = \"${meta.id}.txt\" choice = result . startsWith ( 'snafu' ) ? 'yes' : 'no' \"\"\" echo '${choice}' > '${result}' \"\"\" } /******************************************************************************* * Define main workflow ******************************************************************************/ workflow { ECHO ([ id: 'snafu' ]) } NXF_VER = '21.10.6' nextflow run examples/variable-scope/mixing-solution.nf executor > local (1) [c2/70f706] process > ECHO [100%] 1 of 1 \u2714 Hope this helps, it can be quite baffling.","title":"Mixing variables"}]}